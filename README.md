# ESG Text Classification with Pseudo-Labeling

This project performs ESG (Environmental, Social, Governance) text classification using Transformer-based models combined with Pseudo-labeling and Ensemble Learning techniques.
## ğŸ¯ Overview

The goal of this project is to classify Vietnamese text into ESG-related categories with 4 classes:
- **Class 0**: Irrelevant (Not relevant OR Neutral)
- **Class 1**: Environment (MÃ´i trÆ°á»ng) 
- **Class 2**: Social (XÃ£ há»™i)
- **Class 3**: Governance (Quáº£n trá»‹)

### Äáº·c Ä‘iá»ƒm chÃ­nh:
- **Multi-model training**: Supports 7 different Transformer models
- **Pseudo-labeling with Ensemble Learning**: Automatically labels unlabeled data using ensemble learning techniques

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n
```bash

â”œâ”€â”€ configg/
â”‚   â””â”€â”€ configg.py                      
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv                       # Main training data
â”‚   â”œâ”€â”€ test.csv                        # Test data
â”‚   â”œâ”€â”€ train_subset1.csv               # Training data subsets
â”‚   â”œâ”€â”€ ...                             # Additional subsets (train_subset2.csv - train_subset7.csv)
â”‚   â””â”€â”€ data_pseudo/
â”‚       â””â”€â”€ overall_data.csv           # Unlabeled data
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ esg_model.py                   
â”‚   â””â”€â”€ model_trainer.py               # Model training
â”‚
â”œâ”€â”€ pseudo_labeling/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ pseudo_labeler.py          # Logic pseudo-labeling
â”‚   â”‚   â”œâ”€â”€ data_combiner.py           # Combine original and pseudo-labeled data
â”‚   â”‚   â””â”€â”€ ensemble.py                # Ensemble
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ utils.py  
â”‚  â””â”€â”€ pseudo_labeling_output/         # Pseudo-labeling outputs from each model
â”‚
â”œâ”€â”€ saved_model/                       # save model
â”‚   â”œâ”€â”€ phobert-base/
â”‚   â”œâ”€â”€ bert-base-multilingual-cased/
â”‚   â”œâ”€â”€ distilbert-base-multilingual-cased/
â”‚   â”œâ”€â”€ roberta-base/
â”‚   â”œâ”€â”€ electra-base-vn/
â”‚   â”œâ”€â”€ visobert/
â”‚   â””â”€â”€ videberta-base/
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ metrics.py                     # Evaluation metric functions
â”‚   â””â”€â”€ text_preprocessing.py          
â”‚
â”œâ”€â”€ results/                           # Training results
â”‚   â”œâ”€â”€ phobert-base/
â”‚   â”œâ”€â”€ bert-base-multilingual-cased/
â”‚   â”œâ”€â”€ distilbert-base-multilingual-cased/
â”‚   â”œâ”€â”€ roberta-base/
â”‚   â”œâ”€â”€ electra-base-vn/
â”‚   â”œâ”€â”€ visobert/
â”‚   â””â”€â”€ videberta-base/
â”‚
â”œâ”€â”€ train.py                           
â”œâ”€â”€ train_pseudo.py                    # Pseudo-labeling for a single model
â”œâ”€â”€ train_multiple_models.py           # Train multiple models
â”œâ”€â”€ pseudo_multiple_models.py          # Pseudo-labeling with multiple models
â”œâ”€â”€ evaluate.py                        # Evaluate on test set
â”œâ”€â”€ visualization.ipynb                # Visualize data and results
â”œâ”€â”€ create_subset.py                   # Generate data subsets
â”œâ”€â”€ combiner.py                        # Combine original and pseudo-labeled data
â””â”€â”€ clean_data.py                      # Clean and preprocess data
```

## ğŸš€ How to Run

### 1. Train a Single Model

```bash
python train.py
--train-path data/train.csv
--test-path data/test.csv
--model-name vinai/phobert-base
--epochs 10
--batch-size 16
--max-length 256
--learning-rate 2e-5
```

### 2. Train Multiple Models Simultaneously
```bash
python train_multiple_models.py
``` 
** lÆ°u Ã½: thay Ä‘á»•i tuá»³ chá»n trong code


### 3. Pseudo-labeling with a Single Model
```bash
python train_pseudo.py
--model-path saved_model/phobert-base
--unlabeled-file data/unlabeled.csv
--configdence-threshold 0.9
--max-samples 1000
```

### 4. Pseudo-labeling with Multiple Models
```bash
python pseudo_multiple_models.py
```


### 5. Ensemble voting
```bash
python pseudo_labeling/core/ensemble.py
```

## ğŸ“Š Quy trÃ¬nh Pseudo-labeling

1. **Generate Pseudo Labels**: Trained models predict on unlabeled data
2. **Filter by Confidence**: Retain only predictions with confidence > threshold
3. **Ensemble Voting**: Combine predictions from multiple models
4. **Data Combination**: Merge pseudo-labeled data with original data
5. **Iterative Training**: Re-train models using the combined dataset

## ğŸ“ˆ Metrics vÃ  Evaluation

This project uses the following metrics:
- **Accuracy**
- **Precision**
- **Recall**
- **F1-Score**
- **Confusion Matrix**

## ğŸ” Monitoring vÃ  Logging

- **Hyperparameters and metrics**: Tracking config vÃ  metrics
- **JSON Metadata**: LStore detailed logs of training and pseudo-labeling
- **CSV Results**: export data

**Before running the project, set up the virtual environment:
```bash
conda create -n bert-test python=3.10
conda activate bert-test
pip install -r requirements.txt
```